###  **Detecting LLM vs AI-Written Arabic Text**  
**Classifying Arabic text as AI-generated or human-written using AraBERT and Hugging Face Transformers.**  

---

##  **Project Overview**  
This project focuses on detecting whether an Arabic text was generated by an **AI language model** (LLM) or written by a human. It leverages **AraBERT**, a pre-trained transformer model for Arabic NLP, and fine-tunes it for binary classification. The dataset used in this project was sourced from a private **Kaggle competition**.  

---

##  **Dataset Information**  
The dataset consists of three files:  
- **`train_set.csv`** â†’ Training data with labeled examples (`text`, `generated` column).  
- **`dev_set.csv`** â†’ Development data for model evaluation.  
- **`test_set.csv`** â†’ Test data (without labels) for final predictions.  

 **Note:** Due to competition restrictions, the dataset is **not** included in this repository.  

---

##  **Installation & Setup**  
### **Clone the Repository**  
```bash
git clone https://github.com/safaeOulaja/Detecting_LLM_AI_Arabic_Text.git
cd Detecting_LLM_AI_Arabic_Text
```
---

## ðŸš€ **Training the Model**  
To train the model, run the following command:  
```bash
python scripts/train.py
```
This script:  
âœ” Loads the dataset  
âœ” Cleans and normalizes the Arabic text  
âœ” Tokenizes text using **AraBERT**  
âœ” Fine-tunes the model using **Hugging Face Trainer**  
âœ” Evaluates performance on the validation set  

---

## **Model & Evaluation**  
###  **Architecture**  
- **Base Model:** `aubmindlab/bert-base-arabertv02`  
- **Tokenizer:** `AutoTokenizer`  
- **Classification Head:** Fully connected layer with **2 output neurons** (binary classification).  

###  **Training Settings**  
- **Batch Size:** `16`  
- **Max Sequence Length:** `256`  
- **Learning Rate:** `2e-5`  
- **Optimizer:** AdamW  
- **Epochs:** `3`  

### **Evaluation Metrics**  
- **ROC-AUC Score**  
- **Accuracy**  

After training, the script prints:  
```bash
Dev ROC-AUC: 1.0000
Dev Accuracy: 99.83%
```
---

## **Contributing**  
Contributions are welcome! Please follow these steps:  
1. **Fork** the repository  
2. Create a **new branch** (`feature-branch`)  
3. Commit your changes (`git commit -m "Add new feature"`)  
4. **Push** the branch and create a Pull Request  
---

## **Acknowledgments**  
- **Kaggle Competition** â€“ For providing the plateform for this competition
- **Hugging Face** â€“ For their powerful **transformers library**  
- **AUB Mind Lab** â€“ For developing **AraBERT**  

---
